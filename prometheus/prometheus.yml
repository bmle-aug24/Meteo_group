global:
  scrape_interval: 5s

scrape_configs:
  #- job_name: 'airflow'
    #static_configs:
      # Utilisez le nom de service interne tel que défini dans docker-compose (ici "airflow-webserver")
      #- targets: ['airflow-webserver:8080']

  - job_name: 'api_prediction'
    static_configs:
      # Dans docker-compose, le service "api_prediction" écoute en interne sur le port 8000
      - targets: ['api_prediction:8000']

  - job_name: 'prometheus'
    static_configs:
      # Cette cible permet de scraper Prometheus lui-même
      - targets: ['localhost:9090']
