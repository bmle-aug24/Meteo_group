name: CD for Microservices

on:
  workflow_run:
    workflows: ["CI for Microservices"]
    types:
      - completed

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      # Étape 1 : Récupérer le code source
      - name: Checkout code
        uses: actions/checkout@v3

      # Étape 2 : Installer DVC et récupérer les données depuis DagsHub
      - name: Install DVC & Pull Data
        run: |
          pip install dvc
          dvc remote add origin https://dagshub.com/bmle-aug24/Meteo_group.dvc
          dvc remote modify origin auth basic
          dvc remote modify origin user bmle-aug24
          dvc remote modify origin password 80f0fd7d1ab6a2b1e95664936d78045d71c78e17
          dvc pull

      # Étape 3 : Déployer les services avec Docker Compose
      - name: Deploy with Docker Compose
        run: |
          docker-compose down # Arrêter les services existants
          docker-compose up -d # Lancer les services définis dans docker-compose.yml

      # Étape 4 : Pousser les données versionnées vers DagsHub
      - name: Version RAW Data and Push to DagsHub
        run: |
          dvc add data/raw # Ajouter les données RAW générées par ingestion
          git add data/raw.dvc .gitignore
          git commit -m "Versionnement des données RAW (ingestion)"
          dvc push

      # Étape 5 : Versionner les données traitées et le modèle
      - name: Push Processed Data and Model to DagsHub
        run: |
          dvc add data/processed/X_train.csv
          dvc add data/processed/X_test.csv
          dvc add data/processed/y_train.csv
          dvc add data/processed/y_test.csv
          dvc add mlflow/*
          git add data/processed/*.dvc mlflow/*.dvc .gitignore
          git commit -m "Mise à jour des données traitées et du modèle entraîné"
          dvc push